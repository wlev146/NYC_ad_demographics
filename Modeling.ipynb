{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e23d83ec-e624-46d3-96df-8b6e2c130c4a",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87ac494a-cd9e-42c2-8fd2-b2b3f2b20218",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/24 15:36:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/11/24 15:36:34 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/11/24 15:36:34 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "25/11/24 15:36:34 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "25/11/24 15:36:34 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "25/11/24 15:36:34 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "25/11/24 15:36:34 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
      "25/11/24 15:36:34 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Joined Data Schema ===\n",
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- weekday_num: integer (nullable = true)\n",
      " |-- is_weekend: integer (nullable = true)\n",
      " |-- tod_bucket: string (nullable = true)\n",
      " |-- grid_key: string (nullable = true)\n",
      " |-- borough: string (nullable = true)\n",
      " |-- station_complex: string (nullable = true)\n",
      " |-- flow_sum: long (nullable = true)\n",
      " |-- ridership_sum: long (nullable = true)\n",
      " |-- transfers_sum: long (nullable = true)\n",
      " |-- borough_clean: string (nullable = true)\n",
      " |-- complaints_total: long (nullable = true)\n",
      " |-- complaints_noise: long (nullable = true)\n",
      " |-- complaints_heat: long (nullable = true)\n",
      " |-- complaints_other: long (nullable = true)\n",
      " |-- borough_final: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count: 83449\n",
      "+----------+----+-----------+----------+----------+----------------+-------------+-----------------------------------+--------+-------------+-------------+-------------+----------------+----------------+---------------+----------------+-------------+\n",
      "|date      |hour|weekday_num|is_weekend|tod_bucket|grid_key        |borough      |station_complex                    |flow_sum|ridership_sum|transfers_sum|borough_clean|complaints_total|complaints_noise|complaints_heat|complaints_other|borough_final|\n",
      "+----------+----+-----------+----------+----------+----------------+-------------+-----------------------------------+--------+-------------+-------------+-------------+----------------+----------------+---------------+----------------+-------------+\n",
      "|2024-02-10|3   |7          |1         |Off-Peak  |40.6932_-73.99  |Brooklyn     |Court St (R)/Borough Hall (2,3,4,5)|12      |12           |0            |NULL         |0               |0               |0              |0               |Brooklyn     |\n",
      "|2024-02-07|14  |4          |0         |Off-Peak  |40.6814_-73.88  |Brooklyn     |Norwood Av (J,Z)                   |101     |101          |0            |NULL         |0               |0               |0              |0               |Brooklyn     |\n",
      "|2024-02-09|23  |6          |0         |Off-Peak  |40.7234_-73.9899|Manhattan    |2 Av (F)                           |832     |830          |2            |NULL         |0               |0               |0              |0               |Manhattan    |\n",
      "|2024-02-06|2   |3          |0         |Off-Peak  |40.6551_-74.0036|Brooklyn     |36 St (D,N,R)                      |16      |16           |0            |NULL         |0               |0               |0              |0               |Brooklyn     |\n",
      "|2024-02-10|15  |7          |1         |Off-Peak  |40.6864_-73.9166|Brooklyn     |Halsey St (J)                      |202     |198          |4            |NULL         |0               |0               |0              |0               |Brooklyn     |\n",
      "|2024-02-09|21  |6          |0         |Off-Peak  |40.6369_-74.0748|Staten Island|Tompkinsville (SIR)                |7       |6            |1            |NULL         |0               |0               |0              |0               |Staten Island|\n",
      "|2024-02-09|13  |6          |0         |Off-Peak  |40.7055_-73.8107|Queens       |Sutphin Blvd (F)                   |124     |123          |1            |NULL         |0               |0               |0              |0               |Queens       |\n",
      "|2024-02-12|22  |2          |0         |Off-Peak  |40.6783_-73.912 |Brooklyn     |Rockaway Av (C)                    |44      |44           |0            |NULL         |0               |0               |0              |0               |Brooklyn     |\n",
      "|2024-02-08|21  |5          |0         |Off-Peak  |40.7005_-73.8283|Queens       |121 St (J,Z)                       |30      |27           |3            |NULL         |0               |0               |0              |0               |Queens       |\n",
      "|2024-02-09|14  |6          |0         |Off-Peak  |40.7065_-74.0111|Manhattan    |Broad St (J,Z)                     |310     |309          |1            |NULL         |0               |0               |0              |0               |Manhattan    |\n",
      "+----------+----+-----------+----------+----------+----------------+-------------+-----------------------------------+--------+-------------+-------------+-------------+----------------+----------------+---------------+----------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# start or reuse spark session\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .appName(\"Walrus_Modeling\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "\n",
    "# path to joined parquet folder\n",
    "joined_path = \"/home/wlevine/Walrus/Processed/hourly_panel\"\n",
    "\n",
    "# load the final joined dataframe\n",
    "final_df = spark.read.parquet(joined_path)\n",
    "\n",
    "print(\"=== Joined Data Schema ===\")\n",
    "final_df.printSchema()\n",
    "\n",
    "print(\"Row count:\", final_df.count())\n",
    "\n",
    "final_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f840c10b-9f9e-4825-8aff-b008b5e403ed",
   "metadata": {},
   "source": [
    "## Model 1 - GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67a9ce20-e98b-4ef4-82aa-e9b21d0eb5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modeling row count: 83449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                        (0 + 50) / 50]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|         flow_sum|\n",
      "+-------+-----------------+\n",
      "|  count|            83449|\n",
      "|   mean|274.6747115004374|\n",
      "| stddev| 401.913912972355|\n",
      "|    min|                1|\n",
      "|    25%|               29|\n",
      "|    50%|              122|\n",
      "|    75%|              341|\n",
      "|    max|             4925|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# -----------------------------\n",
    "# prepare modeling dataframe\n",
    "# -----------------------------\n",
    "model_df = (\n",
    "    final_df\n",
    "        .filter(F.col(\"flow_sum\").isNotNull())\n",
    "        .filter(F.col(\"borough_final\").isNotNull())\n",
    "        .fillna({\n",
    "            \"complaints_total\": 0,\n",
    "            \"complaints_noise\": 0,\n",
    "            \"complaints_heat\": 0,\n",
    "            \"complaints_other\": 0\n",
    "        })\n",
    ")\n",
    "\n",
    "print(\"Modeling row count:\", model_df.count())\n",
    "\n",
    "model_df.select(\"flow_sum\").summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4056b05d-bba9-41a0-a658-1aea8b239ac1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 66862\n",
      "Test rows: 16587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred                    \n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/opt/conda/envs/BigDataEnv/lib/python3.12/site-packages/pyspark/jars/spark-core_2.12-3.5.5.jar) to field java.nio.charset.Charset.name\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 323.80\n",
      "R^2 : 0.370\n",
      "+----------+----+-------------+--------+------------------+\n",
      "|date      |hour|borough_final|flow_sum|prediction        |\n",
      "+----------+----+-------------+--------+------------------+\n",
      "|2024-02-05|0   |Brooklyn     |14      |17.224005714177572|\n",
      "|2024-02-05|0   |Brooklyn     |13      |17.224005714177572|\n",
      "|2024-02-05|0   |Brooklyn     |38      |17.224005714177572|\n",
      "|2024-02-05|0   |Brooklyn     |22      |17.224005714177572|\n",
      "|2024-02-05|0   |Brooklyn     |2       |17.224005714177572|\n",
      "|2024-02-05|0   |Queens       |10      |26.76469445939464 |\n",
      "|2024-02-05|0   |Brooklyn     |6       |17.224005714177572|\n",
      "|2024-02-05|0   |Manhattan    |74      |83.7949178889751  |\n",
      "|2024-02-05|0   |Manhattan    |21      |83.7949178889751  |\n",
      "|2024-02-05|0   |Queens       |67      |26.76469445939464 |\n",
      "|2024-02-05|0   |Brooklyn     |37      |17.224005714177572|\n",
      "|2024-02-05|0   |Manhattan    |3       |83.7949178889751  |\n",
      "|2024-02-05|0   |Queens       |41      |26.76469445939464 |\n",
      "|2024-02-05|0   |Manhattan    |37      |83.7949178889751  |\n",
      "|2024-02-05|0   |Bronx        |34      |13.749402875538738|\n",
      "|2024-02-05|0   |Queens       |3       |26.76469445939464 |\n",
      "|2024-02-05|0   |Brooklyn     |3       |17.224005714177572|\n",
      "|2024-02-05|0   |Bronx        |3       |13.749402875538738|\n",
      "|2024-02-05|0   |Brooklyn     |37      |17.224005714177572|\n",
      "|2024-02-05|0   |Brooklyn     |6       |17.224005714177572|\n",
      "+----------+----+-------------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# label\n",
    "label_col = \"flow_sum\"\n",
    "\n",
    "# numeric features (time + complaint load)\n",
    "num_cols = [\n",
    "    \"hour\",\n",
    "    \"weekday_num\",\n",
    "    \"is_weekend\",\n",
    "    \"complaints_total\",\n",
    "    \"complaints_noise\",\n",
    "    \"complaints_heat\",\n",
    "    \"complaints_other\"\n",
    "]\n",
    "\n",
    "# categorical features (keep it clean, not too many levels)\n",
    "cat_cols = [\n",
    "    \"tod_bucket\",      # AM peak / PM peak / Off-Peak\n",
    "    \"borough_final\"    # borough after cleanup\n",
    "]\n",
    "\n",
    "# index + one-hot for categoricals\n",
    "indexers = [\n",
    "    StringIndexer(\n",
    "        inputCol=c,\n",
    "        outputCol=f\"{c}_idx\",\n",
    "        handleInvalid=\"keep\"\n",
    "    )\n",
    "    for c in cat_cols\n",
    "]\n",
    "\n",
    "encoders = [\n",
    "    OneHotEncoder(\n",
    "        inputCols=[f\"{c}_idx\"],\n",
    "        outputCols=[f\"{c}_oh\"]\n",
    "    )\n",
    "    for c in cat_cols\n",
    "]\n",
    "\n",
    "# all feature columns for assembler\n",
    "feature_inputs = num_cols + [f\"{c}_oh\" for c in cat_cols]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_inputs,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# gradient-boosted tree regressor\n",
    "gbt = GBTRegressor(\n",
    "    labelCol=label_col,\n",
    "    featuresCol=\"features\",\n",
    "    maxDepth=6,\n",
    "    maxIter=50,\n",
    "    stepSize=0.1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# pipeline: index -> encode -> assemble -> model\n",
    "stages = indexers + encoders + [assembler, gbt]\n",
    "pipeline = Pipeline(stages=stages)\n",
    "\n",
    "# train / test split\n",
    "train_df, test_df = model_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(\"Train rows:\", train_df.count())\n",
    "print(\"Test rows:\", test_df.count())\n",
    "\n",
    "# fit model\n",
    "gbt_model_pipeline = pipeline.fit(train_df)\n",
    "\n",
    "# predictions on test\n",
    "predictions = gbt_model_pipeline.transform(test_df)\n",
    "\n",
    "# basic regression metrics\n",
    "evaluator_rmse = RegressionEvaluator(\n",
    "    labelCol=label_col,\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "evaluator_r2 = RegressionEvaluator(\n",
    "    labelCol=label_col,\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"r2\"\n",
    ")\n",
    "\n",
    "rmse = evaluator_rmse.evaluate(predictions)\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R^2 : {r2:.3f}\")\n",
    "\n",
    "# quick peek at predictions vs actual\n",
    "predictions.select(\"date\", \"hour\", \"borough_final\",\n",
    "                   \"flow_sum\", \"prediction\") \\\n",
    "           .orderBy(F.col(\"date\"), F.col(\"hour\")) \\\n",
    "           .show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f80bd9e-a265-489f-a0ec-3a6a1ccbf100",
   "metadata": {},
   "source": [
    "##  Model 2 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92f64b1e-32b0-44a6-a38b-fcb5990c9594",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modeling row count: 83449\n",
      "+-------+-----------------+\n",
      "|summary|         flow_sum|\n",
      "+-------+-----------------+\n",
      "|  count|            83449|\n",
      "|   mean|274.6747115004374|\n",
      "| stddev| 401.913912972355|\n",
      "|    min|                1|\n",
      "|    25%|               29|\n",
      "|    50%|              122|\n",
      "|    75%|              341|\n",
      "|    max|             4925|\n",
      "+-------+-----------------+\n",
      "\n",
      "Train rows: 58493\n",
      "Test rows : 24956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/24 15:38:03 WARN DAGScheduler: Broadcasting large task binary with size 1007.3 KiB\n",
      "25/11/24 15:38:04 WARN DAGScheduler: Broadcasting large task binary with size 1594.9 KiB\n",
      "25/11/24 15:38:04 WARN DAGScheduler: Broadcasting large task binary with size 2.3 MiB\n",
      "25/11/24 15:38:05 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "25/11/24 15:38:06 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-------------+--------+------------------+\n",
      "|date      |hour|borough_final|flow_sum|prediction        |\n",
      "+----------+----+-------------+--------+------------------+\n",
      "|2024-02-05|0   |Brooklyn     |10      |27.28531455158018 |\n",
      "|2024-02-05|0   |Queens       |12      |50.09402739218851 |\n",
      "|2024-02-05|0   |Queens       |3       |50.09402739218851 |\n",
      "|2024-02-05|0   |Manhattan    |67      |101.4258571997568 |\n",
      "|2024-02-05|1   |Brooklyn     |4       |23.21512298988411 |\n",
      "|2024-02-05|1   |Manhattan    |20      |61.695911991255564|\n",
      "|2024-02-05|1   |Bronx        |7       |26.761445340599344|\n",
      "|2024-02-05|2   |Queens       |58      |44.66154789806345 |\n",
      "|2024-02-05|2   |Bronx        |1       |26.79365197653512 |\n",
      "|2024-02-05|3   |Brooklyn     |8       |23.56623483225975 |\n",
      "+----------+----+-------------+--------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Random Forest RMSE: 325.36\n",
      "Random Forest R^2 : 0.359\n",
      "RandomForestRegressionModel: uid=RandomForestRegressor_a87c6b4feaa6, numTrees=100, numFeatures=15\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# -----------------------------------\n",
    "# 1. prep modeling dataframe\n",
    "# -----------------------------------\n",
    "\n",
    "# keep rows with real flow + borough info, fill missing complaint counts with 0\n",
    "model_df = (\n",
    "    final_df\n",
    "        .filter(F.col(\"flow_sum\").isNotNull())\n",
    "        .filter(F.col(\"borough_final\").isNotNull())\n",
    "        .fillna({\n",
    "            \"complaints_total\": 0,\n",
    "            \"complaints_noise\": 0,\n",
    "            \"complaints_heat\": 0,\n",
    "            \"complaints_other\": 0\n",
    "        })\n",
    ")\n",
    "\n",
    "print(\"Modeling row count:\", model_df.count())\n",
    "model_df.select(\"flow_sum\").summary().show()\n",
    "\n",
    "# -----------------------------------\n",
    "# 2. categorical encoders\n",
    "# -----------------------------------\n",
    "# going to treat borough + time-of-day bucket as categorical\n",
    "cat_cols = [\"borough_final\", \"tod_bucket\"]\n",
    "indexers = [\n",
    "    StringIndexer(\n",
    "        inputCol=c,\n",
    "        outputCol=f\"{c}_idx\",\n",
    "        handleInvalid=\"keep\"\n",
    "    )\n",
    "    for c in cat_cols\n",
    "]\n",
    "\n",
    "encoders = [\n",
    "    OneHotEncoder(\n",
    "        inputCol=f\"{c}_idx\",\n",
    "        outputCol=f\"{c}_oh\"\n",
    "    )\n",
    "    for c in cat_cols\n",
    "]\n",
    "\n",
    "# -----------------------------------\n",
    "# 3. assemble features\n",
    "# -----------------------------------\n",
    "# basic time signals + complaints + encoded cats\n",
    "feature_cols = [\n",
    "    \"hour\",\n",
    "    \"weekday_num\",\n",
    "    \"is_weekend\",\n",
    "    \"complaints_total\",\n",
    "    \"complaints_noise\",\n",
    "    \"complaints_heat\",\n",
    "    \"complaints_other\",\n",
    "    \"borough_final_oh\",\n",
    "    \"tod_bucket_oh\"\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# -----------------------------------\n",
    "# 4. random forest model\n",
    "# -----------------------------------\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    labelCol=\"flow_sum\",\n",
    "    featuresCol=\"features\",\n",
    "    numTrees=100,\n",
    "    maxDepth=10,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# full pipeline: index -> encode -> assemble -> model\n",
    "stages = []\n",
    "stages.extend(indexers)\n",
    "stages.extend(encoders)\n",
    "stages.append(assembler)\n",
    "stages.append(rf)\n",
    "\n",
    "pipeline = Pipeline(stages=stages)\n",
    "\n",
    "# -----------------------------------\n",
    "# 5. train / test split\n",
    "# -----------------------------------\n",
    "\n",
    "train_df, test_df = model_df.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "print(\"Train rows:\", train_df.count())\n",
    "print(\"Test rows :\", test_df.count())\n",
    "\n",
    "# fit model\n",
    "rf_model = pipeline.fit(train_df)\n",
    "\n",
    "# -----------------------------------\n",
    "# 6. predictions + metrics\n",
    "# -----------------------------------\n",
    "\n",
    "preds = rf_model.transform(test_df)\n",
    "\n",
    "preds.select(\"date\", \"hour\", \"borough_final\", \"flow_sum\", \"prediction\").show(10, truncate=False)\n",
    "\n",
    "evaluator_rmse = RegressionEvaluator(\n",
    "    labelCol=\"flow_sum\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "evaluator_r2 = RegressionEvaluator(\n",
    "    labelCol=\"flow_sum\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"r2\"\n",
    ")\n",
    "\n",
    "rmse = evaluator_rmse.evaluate(preds)\n",
    "r2   = evaluator_r2.evaluate(preds)\n",
    "\n",
    "print(f\"Random Forest RMSE: {rmse:.2f}\")\n",
    "print(f\"Random Forest R^2 : {r2:.3f}\")\n",
    "\n",
    "# if you ever want to inspect tree details:\n",
    "rf_stage = rf_model.stages[-1]\n",
    "print(rf_stage)  # quick summary of the forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eda131-36b0-4934-9948-775a5e226c99",
   "metadata": {},
   "source": [
    "## Humor Score Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f97ad06-4410-4f8c-9057-e595657ab1ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 47.50% for 16 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 44.71% for 17 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 42.22% for 18 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 40.00% for 19 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 38.00% for 20 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 36.19% for 21 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 34.55% for 22 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 33.04% for 23 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 31.67% for 24 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 30.40% for 25 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 29.23% for 26 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 28.15% for 27 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 27.14% for 28 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 26.21% for 29 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 25.33% for 30 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 24.52% for 31 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 23.75% for 32 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 23.03% for 33 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 22.35% for 34 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 21.71% for 35 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 21.11% for 36 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 20.54% for 37 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 20.00% for 38 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 19.49% for 39 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 19.00% for 40 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 18.54% for 41 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 18.10% for 42 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 17.67% for 43 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 17.27% for 44 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 16.89% for 45 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 16.52% for 46 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 16.17% for 47 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 15.83% for 48 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 15.51% for 49 writers\n",
      "25/11/24 15:48:11 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 15.20% for 50 writers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Humor Opportunity Score computed successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 15.51% for 49 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 15.83% for 48 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 16.17% for 47 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 16.52% for 46 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 16.89% for 45 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 17.27% for 44 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 17.67% for 43 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 18.10% for 42 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 18.54% for 41 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 19.00% for 40 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 19.49% for 39 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 20.00% for 38 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 20.54% for 37 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 21.11% for 36 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 21.71% for 35 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 22.35% for 34 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 23.03% for 33 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 23.75% for 32 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 24.52% for 31 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 25.33% for 30 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 26.21% for 29 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 27.14% for 28 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 28.15% for 27 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 29.23% for 26 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 30.40% for 25 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 31.67% for 24 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 33.04% for 23 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 34.55% for 22 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 36.19% for 21 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 38.00% for 20 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 40.00% for 19 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 42.22% for 18 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 44.71% for 17 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 47.50% for 16 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 50.67% for 15 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 54.29% for 14 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 58.46% for 13 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 63.33% for 12 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "25/11/24 15:48:12 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# ============================\n",
    "# 1. NORMALIZE FLOW + COMPLAINTS\n",
    "# ============================\n",
    "\n",
    "# Avoid division by zero by using safe normalizations\n",
    "flow_stats = final_df.agg(F.min(\"flow_sum\").alias(\"min_f\"),\n",
    "                          F.max(\"flow_sum\").alias(\"max_f\")).collect()[0]\n",
    "\n",
    "min_f = flow_stats[\"min_f\"]\n",
    "max_f = flow_stats[\"max_f\"]\n",
    "\n",
    "complaint_stats = final_df.agg(F.min(\"complaints_total\").alias(\"min_c\"),\n",
    "                               F.max(\"complaints_total\").alias(\"max_c\")).collect()[0]\n",
    "\n",
    "min_c = complaint_stats[\"min_c\"]\n",
    "max_c = complaint_stats[\"max_c\"]\n",
    "\n",
    "# add normalized columns\n",
    "df_norm = (\n",
    "    final_df\n",
    "        .withColumn(\n",
    "            \"flow_norm\",\n",
    "            (F.col(\"flow_sum\") - F.lit(min_f)) / (F.lit(max_f - min_f))\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"complaint_norm\",\n",
    "            (F.col(\"complaints_total\") - F.lit(min_c)) / (F.lit(max_c - min_c))\n",
    "        )\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 2. TIME CONTEXT FACTOR\n",
    "# ============================\n",
    "\n",
    "df_time = (\n",
    "    df_norm\n",
    "        .withColumn(\n",
    "            \"time_factor\",\n",
    "            F.when(F.col(\"tod_bucket\") == \"AM Peak\", 1.0)\n",
    "             .when(F.col(\"tod_bucket\") == \"PM Peak\", 0.9)\n",
    "             .otherwise(0.4)\n",
    "        )\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 3. BUILD HUMOR OPPORTUNITY SCORE\n",
    "# ============================\n",
    "\n",
    "df_humor = (\n",
    "    df_time\n",
    "        .withColumn(\n",
    "            \"humor_score\",\n",
    "            0.50 * F.col(\"flow_norm\") +\n",
    "            0.35 * F.col(\"complaint_norm\") +\n",
    "            0.15 * F.col(\"time_factor\")\n",
    "        )\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 4. SAVE THE RESULTS FOR VISUALIZATION LATER\n",
    "# ============================\n",
    "\n",
    "df_humor.write.mode(\"overwrite\").parquet(\"/home/wlevine/Walrus/Processed/humor_score_panel\")\n",
    "\n",
    "print(\"Humor Opportunity Score computed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigDataEnv",
   "language": "python",
   "name": "bigdataenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
